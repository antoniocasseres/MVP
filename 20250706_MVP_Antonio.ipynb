{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniocasseres/MVP/blob/main/20250706_MVP_Antonio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# MVP Análise de Dados e Boas Práticas\n",
        "\n",
        "**Nome:** Antonio Casseres  \n",
        "**Matrícula:** 4052025000769  \n",
        "**Dataset:** [Wine Quality Dataset](https://archive.ics.uci.edu/dataset/186/wine+quality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "problem_description"
      },
      "source": [
        "## Descrição do Problema\n",
        "\n",
        "O conjunto de dados Wine Quality é um conjunto de dados multivariado que consiste em medidas físico-químicas de vinhos portugueses (tintos e brancos). O objetivo principal é analisar e prever a qualidade do vinho com base em onze características químicas: acidez fixa, acidez volátil, ácido cítrico, açúcar residual, cloretos, dióxido de enxofre livre, dióxido de enxofre total, densidade, pH, sulfatos e teor alcoólico.\n",
        "\n",
        "### Hipóteses do Problema\n",
        "\n",
        "As hipóteses que tracei são as seguintes:\n",
        "\n",
        "• O teor alcoólico tem correlação positiva significativa com a qualidade do vinho?\n",
        "• A acidez volátil afeta negativamente a percepção de qualidade?\n",
        "• Existe diferença na distribuição de qualidade entre vinhos tintos e brancos?\n",
        "• As características químicas permitem distinguir vinhos de alta qualidade dos demais?\n",
        "\n",
        "### Categorização do Problema\n",
        "\n",
        "Este é um problema de **aprendizado supervisionado**.\n",
        "\n",
        "**Justificativa:**\n",
        "• Possuímos uma variável target bem definida: 'quality' (qualidade do vinho)\n",
        "• Cada amostra possui um rótulo conhecido (qualidade avaliada por especialistas)\n",
        "• O objetivo é prever/classificar a qualidade baseada nas características físico-químicas\n",
        "• Temos 6.497 exemplos rotulados para treinar modelos preditivos\n",
        "\n",
        "**Subtipo do Problema Supervisionado:**\n",
        "• **Classificação**: Tratar qualidade como classes discretas (3, 4, 5, 6, 7, 8, 9)\n",
        "• **Regressão**: Tratar qualidade como variável contínua ordinal\n",
        "\n",
        "**Diferenciação:**\n",
        "• Não é não supervisionado pois não buscamos apenas padrões ocultos\n",
        "• Não é clustering pois temos rótulos definidos\n",
        "• Não é detecção de anomalias como objetivo principal\n",
        "\n",
        "### Tipo de Problema\n",
        "\n",
        "Este é um problema de **análise exploratória e pré-processamento de dados**. Dado um conjunto de características físico-químicas, o objetivo é entender os padrões, correlações e distribuições que influenciam a qualidade do vinho, preparando os dados para modelagem futura."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_selection"
      },
      "source": [
        "## Seleção de Dados\n",
        "\n",
        "O dataset Wine Quality é um conjunto de dados amplamente disponível e frequentemente incluído em bibliotecas de aprendizado de máquina. Os dados estão disponíveis no repositório GitHub pessoal e serão carregados diretamente via URL, garantindo reprodutibilidade e acesso controlado aos dados.\n",
        "\n",
        "### Atributos do Dataset\n",
        "\n",
        "O dataset Wine Quality contém 6.497 amostras (1.599 vinhos tintos + 4.898 vinhos brancos), com doze atributos:\n",
        "\n",
        "• **fixed acidity** (acidez fixa em g/dm³)\n",
        "• **volatile acidity** (acidez volátil em g/dm³)\n",
        "• **citric acid** (ácido cítrico em g/dm³)\n",
        "• **residual sugar** (açúcar residual em g/dm³)\n",
        "• **chlorides** (cloretos em g/dm³)\n",
        "• **free sulfur dioxide** (dióxido de enxofre livre em mg/dm³)\n",
        "• **total sulfur dioxide** (dióxido de enxofre total em mg/dm³)\n",
        "• **density** (densidade em g/cm³)\n",
        "• **pH** (potencial hidrogeniônico)\n",
        "• **sulphates** (sulfatos em g/dm³)\n",
        "• **alcohol** (teor alcoólico em % vol.)\n",
        "• **quality** (qualidade - variável target, escala de 0 a 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_section"
      },
      "source": [
        "## Importação das Bibliotecas Necessárias e Carga de Dados\n",
        "\n",
        "Esta seção consolida todas as importações de bibliotecas necessárias para a análise, visualização e pré-processamento dos dados, bem como o carregamento inicial do dataset Wine Quality do repositório GitHub pessoal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas essenciais\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurações de visualização\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Carregamento do dataset Wine Quality do repositório GitHub pessoal\n",
        "# URLs dos arquivos no repositório GitHub\n",
        "url_red = \"https://raw.githubusercontent.com/antoniocasseres/MVP/refs/heads/main/winequality-red.csv\"\n",
        "url_white = \"https://raw.githubusercontent.com/antoniocasseres/MVP/refs/heads/main/winequality-white.csv\"\n",
        "\n",
        "# Carrega dados de vinho tinto\n",
        "df_red = pd.read_csv(url_red, sep=';')\n",
        "df_red['wine_type'] = 'red'\n",
        "\n",
        "# Carrega dados de vinho branco\n",
        "df_white = pd.read_csv(url_white, sep=';')\n",
        "df_white['wine_type'] = 'white'\n",
        "\n",
        "# Combina os datasets\n",
        "df = pd.concat([df_red, df_white], ignore_index=True)\n",
        "\n",
        "print(f\"Dataset carregado com sucesso do repositório GitHub!\")\n",
        "print(f\"Dimensões: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
        "print(f\"Tipos de vinho: {df['wine_type'].value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "first_look"
      },
      "outputs": [],
      "source": [
        "# Primeiras linhas do dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_analysis"
      },
      "source": [
        "## Análise de Dados\n",
        "\n",
        "Nesta etapa de Análise de Dados Exploratória (EDA) sobre o dataset Wine Quality, visamos entender a distribuição, as relações e as características das variáveis, o que é crucial para as etapas subsequentes de pré-processamento e modelagem supervisionada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "total_instances"
      },
      "source": [
        "### Total e Tipo das Instâncias\n",
        "\n",
        "O dataset Wine Quality possui 6.497 instâncias (observações), combinando vinhos tintos e brancos. As onze características de medição são do tipo numérico (float), enquanto os atributos 'wine_type' e 'quality' são categóricos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_info"
      },
      "outputs": [],
      "source": [
        "# Informações gerais do dataset\n",
        "print(f\"Total de instâncias: {len(df)}\")\n",
        "print(f\"Total de features: {len(df.columns)}\")\n",
        "print(f\"Variável target: quality (supervisionado)\")\n",
        "print(\"\\nTipos de dados por coluna:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nValores ausentes por coluna:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wine_distribution"
      },
      "outputs": [],
      "source": [
        "# Distribuição por tipo de vinho\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Gráfico de pizza\n",
        "plt.subplot(1, 2, 1)\n",
        "wine_counts = df['wine_type'].value_counts()\n",
        "plt.pie(wine_counts.values, labels=wine_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Distribuição dos Tipos de Vinho')\n",
        "plt.axis('equal')\n",
        "\n",
        "# Gráfico de barras\n",
        "plt.subplot(1, 2, 2)\n",
        "wine_counts.plot(kind='bar', color=['darkred', 'gold'])\n",
        "plt.title('Contagem por Tipo de Vinho')\n",
        "plt.xlabel('Tipo de Vinho')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Vinhos brancos: {wine_counts['white']} ({wine_counts['white']/len(df)*100:.1f}%)\")\n",
        "print(f\"Vinhos tintos: {wine_counts['red']} ({wine_counts['red']/len(df)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "descriptive_stats"
      },
      "source": [
        "### Estatísticas Descritivas\n",
        "\n",
        "Estatísticas descritivas fornecem um resumo das características numéricas, incluindo média, desvio padrão, mínimo, máximo e quartis. Foco especial na variável target para problemas supervisionados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "describe_data"
      },
      "outputs": [],
      "source": [
        "# Estatísticas descritivas básicas do dataset\n",
        "print(\"Estatísticas Descritivas Completas:\")\n",
        "print(\"=\" * 40)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quality_analysis"
      },
      "outputs": [],
      "source": [
        "# Análise específica da variável target (quality) - Foco supervisionado\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Distribuição da qualidade\n",
        "plt.subplot(2, 2, 1)\n",
        "quality_counts = df['quality'].value_counts().sort_index()\n",
        "plt.bar(quality_counts.index, quality_counts.values, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribuição da Variável Target (Quality)')\n",
        "plt.xlabel('Qualidade (0-10)')\n",
        "plt.ylabel('Frequência')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Qualidade por tipo de vinho\n",
        "plt.subplot(2, 2, 2)\n",
        "df.boxplot(column='quality', by='wine_type', ax=plt.gca())\n",
        "plt.title('Qualidade por Tipo de Vinho')\n",
        "plt.suptitle('')  # Remove título automático\n",
        "\n",
        "# Histograma da qualidade\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.hist(df['quality'], bins=range(3, 11), alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "plt.title('Histograma da Qualidade')\n",
        "plt.xlabel('Qualidade')\n",
        "plt.ylabel('Frequência')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Qualidade média por tipo\n",
        "plt.subplot(2, 2, 4)\n",
        "quality_by_type = df.groupby('wine_type')['quality'].agg(['mean', 'std']).round(2)\n",
        "quality_by_type['mean'].plot(kind='bar', color=['darkred', 'gold'],\n",
        "                            yerr=quality_by_type['std'], capsize=5)\n",
        "plt.title('Qualidade Média por Tipo de Vinho')\n",
        "plt.xlabel('Tipo de Vinho')\n",
        "plt.ylabel('Qualidade Média')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nEstatísticas da Variável Target (Quality):\")\n",
        "print(f\"Média: {df['quality'].mean():.2f}\")\n",
        "print(f\"Mediana: {df['quality'].median():.2f}\")\n",
        "print(f\"Desvio Padrão: {df['quality'].std():.2f}\")\n",
        "print(f\"Amplitude: {df['quality'].min()} - {df['quality'].max()}\")\n",
        "print(f\"Classes únicas: {sorted(df['quality'].unique())}\")\n",
        "print(f\"Balanceamento das classes:\")\n",
        "for quality, count in quality_counts.items():\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"  Qualidade {quality}: {count:4d} ({percentage:5.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "correlation_analysis"
      },
      "source": [
        "### Análise de Correlação\n",
        "\n",
        "A análise de correlação nos ajuda a identificar relações lineares entre as variáveis numéricas, especialmente com a variável target (quality). Essencial para problemas supervisionados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "correlation_matrix"
      },
      "outputs": [],
      "source": [
        "# Matriz de correlação\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "\n",
        "# Visualização da matriz de correlação\n",
        "plt.figure(figsize=(14, 12))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, fmt='.2f')\n",
        "plt.title('Matriz de Correlação - Características Físico-Químicas')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlações com a qualidade (variável target)\n",
        "quality_corr = correlation_matrix['quality'].abs().sort_values(ascending=False)\n",
        "print(\"\\nCorrelações com a Variável Target (Quality):\")\n",
        "print(\"=\" * 50)\n",
        "for feature, corr in quality_corr.items():\n",
        "    if feature != 'quality':\n",
        "        direction = \"positiva\" if correlation_matrix['quality'][feature] > 0 else \"negativa\"\n",
        "        strength = \"forte\" if abs(correlation_matrix['quality'][feature]) > 0.3 else \"moderada\" if abs(correlation_matrix['quality'][feature]) > 0.1 else \"fraca\"\n",
        "        print(f\"• {feature:20s}: {correlation_matrix['quality'][feature]:+.3f} ({direction}, {strength})\")\n",
        "\n",
        "# Top 5 features mais correlacionadas\n",
        "top_features = quality_corr.drop('quality').head(5)\n",
        "print(f\"\\nTop 5 Features mais correlacionadas com Quality:\")\n",
        "for i, (feature, corr) in enumerate(top_features.items(), 1):\n",
        "    print(f\"{i}. {feature}: {correlation_matrix['quality'][feature]:+.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "distribution_analysis"
      },
      "source": [
        "### Análise de Distribuições\n",
        "\n",
        "Analisamos as distribuições das principais variáveis para identificar padrões, assimetrias e possíveis outliers. Foco nas features mais correlacionadas com a variável target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_distributions"
      },
      "outputs": [],
      "source": [
        "# Distribuições das features mais correlacionadas com qualidade\n",
        "top_features_list = quality_corr.drop('quality').head(6).index.tolist()\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
        "fig.suptitle('Distribuições das Features Mais Importantes para Predição', fontsize=16)\n",
        "\n",
        "for i, feature in enumerate(top_features_list):\n",
        "    row, col = i // 2, i % 2\n",
        "\n",
        "    # Histograma com curva de densidade\n",
        "    axes[row, col].hist(df[feature], bins=30, alpha=0.7, density=True,\n",
        "                       color='skyblue', edgecolor='black')\n",
        "    df[feature].plot.density(ax=axes[row, col], color='red', linewidth=2)\n",
        "\n",
        "    # Adiciona estatísticas\n",
        "    mean_val = df[feature].mean()\n",
        "    median_val = df[feature].median()\n",
        "    axes[row, col].axvline(mean_val, color='green', linestyle='--', alpha=0.7, label=f'Média: {mean_val:.2f}')\n",
        "    axes[row, col].axvline(median_val, color='orange', linestyle='--', alpha=0.7, label=f'Mediana: {median_val:.2f}')\n",
        "\n",
        "    axes[row, col].set_title(f'{feature}\\n(Corr. c/ qualidade: {correlation_matrix[\"quality\"][feature]:+.3f})')\n",
        "    axes[row, col].set_xlabel(feature)\n",
        "    axes[row, col].set_ylabel('Densidade')\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "    axes[row, col].legend(fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Análise de normalidade das principais features\n",
        "print(\"\\nTeste de Normalidade (Shapiro-Wilk) - Amostra de 5000:\")\n",
        "print(\"=\" * 60)\n",
        "sample_size = min(5000, len(df))\n",
        "df_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "for feature in top_features_list:\n",
        "    statistic, p_value = stats.shapiro(df_sample[feature])\n",
        "    is_normal = \"Normal\" if p_value > 0.05 else \"Não Normal\"\n",
        "    print(f\"• {feature:20s}: p-value = {p_value:.2e} ({is_normal})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outlier_analysis"
      },
      "source": [
        "### Detecção de Outliers\n",
        "\n",
        "Utilizamos o método IQR (Interquartile Range) para identificar outliers nas variáveis numéricas. Importante para preparação de dados supervisionados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "outlier_detection"
      },
      "outputs": [],
      "source": [
        "# Função para detectar outliers usando IQR\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "    return len(outliers), lower_bound, upper_bound\n",
        "\n",
        "# Análise de outliers\n",
        "print(\"Detecção de Outliers (Método IQR):\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "outlier_summary = {}\n",
        "total_outliers = 0\n",
        "\n",
        "for feature in numeric_cols.drop('quality'):\n",
        "    outlier_count, lower, upper = detect_outliers_iqr(df, feature)\n",
        "    outlier_percentage = (outlier_count / len(df)) * 100\n",
        "    outlier_summary[feature] = outlier_count\n",
        "    total_outliers += outlier_count\n",
        "    print(f\"• {feature:20s}: {outlier_count:4d} outliers ({outlier_percentage:5.2f}%) [{lower:.2f}, {upper:.2f}]\")\n",
        "\n",
        "print(f\"\\nTotal de outliers detectados: {total_outliers}\")\n",
        "print(f\"Percentual total de outliers: {(total_outliers / (len(df) * len(numeric_cols.drop('quality'))))*100:.2f}%\")\n",
        "\n",
        "# Visualização de outliers via boxplots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Boxplots - Detecção Visual de Outliers (Top 6 Features)', fontsize=16)\n",
        "\n",
        "for i, feature in enumerate(top_features_list):\n",
        "    row, col = i // 3, i % 3\n",
        "    df.boxplot(column=feature, ax=axes[row, col])\n",
        "    axes[row, col].set_title(f'{feature}\\n({outlier_summary[feature]} outliers)')\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Outliers por qualidade (análise supervisionada)\n",
        "print(\"\\nOutliers por Classe de Qualidade:\")\n",
        "print(\"=\" * 35)\n",
        "for quality in sorted(df['quality'].unique()):\n",
        "    quality_data = df[df['quality'] == quality]\n",
        "    quality_outliers = 0\n",
        "    for feature in numeric_cols.drop('quality'):\n",
        "        outlier_count, _, _ = detect_outliers_iqr(quality_data, feature)\n",
        "        quality_outliers += outlier_count\n",
        "    print(f\"• Qualidade {quality}: {quality_outliers:3d} outliers ({len(quality_data):4d} amostras)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing_section"
      },
      "source": [
        "## Pré-processamento de Dados\n",
        "\n",
        "Esta seção implementa técnicas de pré-processamento específicas para problemas de aprendizado supervisionado, preparando os dados para modelagem preditiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_cleaning"
      },
      "source": [
        "### Limpeza de Dados\n",
        "\n",
        "Verificação e tratamento de valores ausentes, duplicatas e inconsistências."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_cleaning_code"
      },
      "outputs": [],
      "source": [
        "# Cria cópia para pré-processamento\n",
        "df_processed = df.copy()\n",
        "\n",
        "print(\"Limpeza de Dados:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Verifica valores ausentes\n",
        "missing_values = df_processed.isnull().sum()\n",
        "print(f\"Valores ausentes: {missing_values.sum()}\")\n",
        "if missing_values.sum() > 0:\n",
        "    print(\"Colunas com valores ausentes:\")\n",
        "    for col, missing in missing_values[missing_values > 0].items():\n",
        "        print(f\"  {col}: {missing}\")\n",
        "\n",
        "# Verifica duplicatas\n",
        "initial_rows = len(df_processed)\n",
        "print(f\"\\nLinhas antes da limpeza: {initial_rows}\")\n",
        "\n",
        "# Remove duplicatas mantendo wine_type\n",
        "df_processed = df_processed.drop_duplicates()\n",
        "removed_duplicates = initial_rows - len(df_processed)\n",
        "print(f\"Duplicatas removidas: {removed_duplicates}\")\n",
        "\n",
        "# Verifica consistência dos dados\n",
        "print(f\"\\nVerificação de Consistência:\")\n",
        "print(f\"Qualidade mín/máx: {df_processed['quality'].min()}/{df_processed['quality'].max()}\")\n",
        "print(f\"Valores negativos em features: {(df_processed[numeric_cols.drop('quality')] < 0).sum().sum()}\")\n",
        "\n",
        "print(f\"\\nDataset após limpeza: {df_processed.shape}\")\n",
        "print(f\"Colunas disponíveis: {list(df_processed.columns)}\")\n",
        "print(f\"wine_type preservado: {'wine_type' in df_processed.columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outlier_treatment"
      },
      "source": [
        "### Tratamento de Outliers\n",
        "\n",
        "Aplicação de winsorização (capping) para tratar outliers extremos, preservando a distribuição geral dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "outlier_treatment_code"
      },
      "outputs": [],
      "source": [
        "# Função para winsorização\n",
        "def winsorize_feature(data, column, lower_percentile=0.05, upper_percentile=0.95):\n",
        "    lower_bound = data[column].quantile(lower_percentile)\n",
        "    upper_bound = data[column].quantile(upper_percentile)\n",
        "\n",
        "    # Conta outliers antes do tratamento\n",
        "    outliers_before = len(data[(data[column] < lower_bound) | (data[column] > upper_bound)])\n",
        "\n",
        "    # Aplica capping (winsorização)\n",
        "    data[column] = data[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "    return outliers_before\n",
        "\n",
        "print(\"Tratamento de Outliers (Winsorização 5%-95%):\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Aplica winsorização em features numéricas (exceto target)\n",
        "numeric_cols_processed = df_processed.select_dtypes(include=[np.number]).columns\n",
        "features_to_winsorize = [col for col in numeric_cols_processed if col != 'quality']\n",
        "total_outliers_treated = 0\n",
        "\n",
        "# Estatísticas antes do tratamento\n",
        "stats_before = df_processed[features_to_winsorize].describe()\n",
        "\n",
        "for feature in features_to_winsorize:\n",
        "    outliers_treated = winsorize_feature(df_processed, feature)\n",
        "    total_outliers_treated += outliers_treated\n",
        "    print(f\"• {feature:20s}: {outliers_treated:3d} outliers tratados\")\n",
        "\n",
        "# Estatísticas após o tratamento\n",
        "stats_after = df_processed[features_to_winsorize].describe()\n",
        "\n",
        "print(f\"\\nTotal de outliers tratados: {total_outliers_treated}\")\n",
        "print(f\"Percentual de dados modificados: {(total_outliers_treated/len(df_processed))*100:.2f}%\")\n",
        "\n",
        "# Comparação antes/depois para feature mais importante\n",
        "most_important_feature = top_features_list[0]\n",
        "print(f\"\\nComparação {most_important_feature} (feature mais correlacionada):\")\n",
        "print(f\"Antes  - Mín: {stats_before[most_important_feature]['min']:.3f}, Máx: {stats_before[most_important_feature]['max']:.3f}\")\n",
        "print(f\"Depois - Mín: {stats_after[most_important_feature]['min']:.3f}, Máx: {stats_after[most_important_feature]['max']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature_engineering"
      },
      "source": [
        "### Feature Engineering\n",
        "\n",
        "Criação de novas variáveis baseadas no conhecimento do domínio para melhorar a capacidade preditiva do modelo supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_engineering_code"
      },
      "outputs": [],
      "source": [
        "print(\"Feature Engineering:\")\n",
        "print(\"=\" * 20)\n",
        "\n",
        "# 1. Razão acidez total / pH (indicador de equilíbrio ácido)\n",
        "df_processed['acidity_ph_ratio'] = (df_processed['fixed acidity'] + df_processed['volatile acidity']) / df_processed['pH']\n",
        "print(\"• Criada: acidity_ph_ratio (equilíbrio ácido)\")\n",
        "\n",
        "# 2. Razão SO2 livre / SO2 total (eficiência da preservação)\n",
        "df_processed['sulfur_ratio'] = df_processed['free sulfur dioxide'] / (df_processed['total sulfur dioxide'] + 1e-8)\n",
        "print(\"• Criada: sulfur_ratio (eficiência preservação)\")\n",
        "\n",
        "# 3. Indicador de vinho doce (baseado no quartil superior)\n",
        "sugar_threshold = df_processed['residual sugar'].quantile(0.75)\n",
        "df_processed['is_sweet'] = (df_processed['residual sugar'] > sugar_threshold).astype(int)\n",
        "print(f\"• Criada: is_sweet (threshold: {sugar_threshold:.2f} g/dm³)\")\n",
        "\n",
        "# 4. Categoria de álcool (baixo, médio, alto)\n",
        "df_processed['alcohol_category'] = pd.cut(df_processed['alcohol'],\n",
        "                                         bins=[0, 10, 12, 15],\n",
        "                                         labels=['Baixo', 'Médio', 'Alto'])\n",
        "print(\"• Criada: alcohol_category (Baixo: <10%, Médio: 10-12%, Alto: >12%)\")\n",
        "\n",
        "# 5. Densidade ajustada (densidade - álcool, pois álcool reduz densidade)\n",
        "df_processed['density_adjusted'] = df_processed['density'] + (df_processed['alcohol'] * 0.001)\n",
        "print(\"• Criada: density_adjusted (densidade corrigida pelo álcool)\")\n",
        "\n",
        "print(f\"\\nTotal de features após engineering: {len(df_processed.columns)}\")\n",
        "print(f\"Novas features criadas: 5\")\n",
        "\n",
        "# Verifica correlação das novas features com target\n",
        "new_features = ['acidity_ph_ratio', 'sulfur_ratio', 'is_sweet', 'density_adjusted']\n",
        "print(f\"\\nCorrelação das novas features com quality:\")\n",
        "for feature in new_features:\n",
        "    corr = df_processed[feature].corr(df_processed['quality'])\n",
        "    print(f\"• {feature:20s}: {corr:+.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "encoding"
      },
      "source": [
        "### Codificação de Variáveis Categóricas\n",
        "\n",
        "Transformação de variáveis categóricas em formato numérico adequado para algoritmos de aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "encoding_code"
      },
      "outputs": [],
      "source": [
        "print(\"Codificação de Variáveis Categóricas:\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# Verifica colunas categóricas disponíveis\n",
        "categorical_cols = df_processed.select_dtypes(include=['object', 'category']).columns\n",
        "print(f\"Colunas categóricas encontradas: {list(categorical_cols)}\")\n",
        "\n",
        "# Codifica wine_type se existir\n",
        "if 'wine_type' in df_processed.columns:\n",
        "    # Label Encoding para wine_type (binária: red=0, white=1)\n",
        "    le_wine_type = LabelEncoder()\n",
        "    df_processed['wine_type_encoded'] = le_wine_type.fit_transform(df_processed['wine_type'])\n",
        "    mapping = dict(zip(le_wine_type.classes_, le_wine_type.transform(le_wine_type.classes_)))\n",
        "    print(f\"• wine_type codificado: {mapping}\")\n",
        "\n",
        "    # Remove coluna original\n",
        "    df_processed = df_processed.drop(['wine_type'], axis=1)\n",
        "else:\n",
        "    print(\"• wine_type: Coluna não encontrada\")\n",
        "\n",
        "# Codifica alcohol_category se existir\n",
        "if 'alcohol_category' in df_processed.columns:\n",
        "    # One-Hot Encoding para alcohol_category (ordinal, mas poucas categorias)\n",
        "    alcohol_dummies = pd.get_dummies(df_processed['alcohol_category'], prefix='alcohol', drop_first=True)\n",
        "    df_processed = pd.concat([df_processed, alcohol_dummies], axis=1)\n",
        "    print(f\"• alcohol_category: One-Hot Encoding aplicado ({len(alcohol_dummies.columns)} colunas criadas)\")\n",
        "\n",
        "    # Remove coluna original\n",
        "    df_processed = df_processed.drop(['alcohol_category'], axis=1)\n",
        "else:\n",
        "    print(\"• alcohol_category: Coluna não encontrada\")\n",
        "\n",
        "# Verifica se restaram colunas categóricas\n",
        "remaining_categorical = df_processed.select_dtypes(include=['object', 'category']).columns\n",
        "if len(remaining_categorical) > 0:\n",
        "    print(f\"\\nColunas categóricas restantes: {list(remaining_categorical)}\")\n",
        "else:\n",
        "    print(f\"\\n Todas as variáveis categóricas foram codificadas\")\n",
        "\n",
        "print(f\"\\nDataset após codificação: {df_processed.shape}\")\n",
        "print(f\"Tipos de dados finais:\")\n",
        "print(df_processed.dtypes.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "normalization"
      },
      "source": [
        "### Normalização dos Dados\n",
        "\n",
        "Aplicação de StandardScaler para normalizar as features numéricas, essencial para algoritmos sensíveis à escala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "normalization_code"
      },
      "outputs": [],
      "source": [
        "# Separação de features e target\n",
        "X = df_processed.drop('quality', axis=1)\n",
        "y = df_processed['quality']\n",
        "\n",
        "print(\"Normalização dos Dados:\")\n",
        "print(\"=\" * 25)\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "print(f\"Problema: Supervisionado (target = quality)\")\n",
        "\n",
        "# Identifica colunas binárias (não precisam normalização)\n",
        "binary_columns = []\n",
        "for col in X.columns:\n",
        "    unique_vals = X[col].nunique()\n",
        "    if unique_vals == 2 and set(X[col].unique()).issubset({0, 1}):\n",
        "        binary_columns.append(col)\n",
        "\n",
        "columns_to_normalize = [col for col in X.columns if col not in binary_columns]\n",
        "\n",
        "print(f\"\\nColunas para normalização: {len(columns_to_normalize)}\")\n",
        "print(f\"Colunas binárias (preservadas): {len(binary_columns)}\")\n",
        "if binary_columns:\n",
        "    print(f\"Colunas binárias: {binary_columns}\")\n",
        "\n",
        "# Aplica StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = X.copy()\n",
        "\n",
        "if len(columns_to_normalize) > 0:\n",
        "    X_normalized[columns_to_normalize] = scaler.fit_transform(X[columns_to_normalize])\n",
        "\n",
        "    # Verifica normalização\n",
        "    normalized_stats = X_normalized[columns_to_normalize].describe()\n",
        "    print(f\"\\nVerificação da normalização:\")\n",
        "    print(f\"Média máxima: {normalized_stats.loc['mean'].abs().max():.6f} (deve ser ~0)\")\n",
        "    print(f\"Desvio padrão máximo: {normalized_stats.loc['std'].max():.6f} (deve ser ~1)\")\n",
        "    print(f\"Desvio padrão mínimo: {normalized_stats.loc['std'].min():.6f} (deve ser ~1)\")\n",
        "else:\n",
        "    print(\"\\nNenhuma coluna foi normalizada (apenas binárias encontradas)\")\n",
        "\n",
        "# Estatísticas da variável target\n",
        "print(f\"\\nEstatísticas da variável target (quality):\")\n",
        "print(f\"Distribuição: {y.value_counts().sort_index().to_dict()}\")\n",
        "print(f\"Balanceamento: {(y.value_counts() / len(y) * 100).round(1).to_dict()}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_dataset"
      },
      "source": [
        "### Dataset Final\n",
        "\n",
        "Preparação e salvamento do dataset processado, pronto para modelagem supervisionada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_dataset_code",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Dataset final\n",
        "df_final = X_normalized.copy()\n",
        "df_final['quality'] = y\n",
        "\n",
        "print(\"Dataset Final Processado:\")\n",
        "print(\"=\" * 30)\n",
        "print(f\"Dimensões: {df_final.shape}\")\n",
        "print(f\"Features: {df_final.shape[1] - 1}\")\n",
        "print(f\"Amostras: {df_final.shape[0]}\")\n",
        "print(f\"Tipo de problema: Supervisionado\")\n",
        "print(f\"Variável target: quality\")\n",
        "\n",
        "# Distribuição final da qualidade\n",
        "print(f\"\\nDistribuição Final da Variável Target:\")\n",
        "quality_dist = df_final['quality'].value_counts().sort_index()\n",
        "for quality, count in quality_dist.items():\n",
        "    percentage = (count / len(df_final)) * 100\n",
        "    print(f\"• Qualidade {quality}: {count:4d} ({percentage:5.1f}%)\")\n",
        "\n",
        "# Informações sobre features\n",
        "print(f\"\\nTipos de Features no Dataset Final:\")\n",
        "feature_types = df_final.drop('quality', axis=1).dtypes.value_counts()\n",
        "for dtype, count in feature_types.items():\n",
        "    print(f\"• {dtype}: {count} features\")\n",
        "\n",
        "# Verifica qualidade dos dados\n",
        "print(f\"\\nQualidade dos Dados Finais:\")\n",
        "print(f\"• Valores ausentes: {df_final.isnull().sum().sum()}\")\n",
        "print(f\"• Valores infinitos: {np.isinf(df_final.select_dtypes(include=[np.number])).sum().sum()}\")\n",
        "print(f\"• Duplicatas: {df_final.duplicated().sum()}\")\n",
        "\n",
        "# Salva dataset processado\n",
        "df_final.to_csv('wine_quality_processed.csv', index=False)\n",
        "print(f\"\\n Dataset salvo como: wine_quality_processed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xn79zNrwgRx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusions"
      },
      "source": [
        "## Conclusões e Próximos Passos\n",
        "\n",
        "### Principais Descobertas:\n",
        "\n",
        "1. **Problema Supervisionado Confirmado**: O dataset possui uma variável target bem definida (quality) com 6.497 exemplos rotulados, adequado para classificação ou regressão.\n",
        "\n",
        "2. **Correlações Identificadas**: O teor alcoólico mostrou a correlação positiva mais forte com a qualidade, enquanto a acidez volátil apresentou a correlação negativa mais significativa.\n",
        "\n",
        "3. **Distribuição da Target**: A maioria dos vinhos concentra-se nas qualidades 5-7 (85% dos dados), com poucos exemplares de qualidade extrema, indicando um problema de classificação com classes desbalanceadas.\n",
        "\n",
        "4. **Outliers Tratados**: Foram identificados e tratados outliers em todas as variáveis numéricas usando winsorização, preservando a distribuição geral dos dados.\n",
        "\n",
        "5. **Features Engineered**: Cinco novas variáveis foram criadas baseadas no conhecimento do domínio, incluindo razões químicas e indicadores categóricos que podem melhorar a capacidade preditiva.\n",
        "\n",
        "6. **Dataset Balanceado**: O dataset final contém dados normalizados, codificados e prontos para algoritmos de aprendizado supervisionado.\n",
        "\n",
        "### Insights para Modelagem Supervisionada:\n",
        "\n",
        "• **Features mais importantes**: alcohol, volatile acidity, sulphates, citric acid\n",
        "• **Estratégia recomendada**: Classificação multiclasse ou regressão ordinal\n",
        "• **Desafios**: Classes desbalanceadas (qualidades 3, 4, 8, 9 são raras)\n",
        "• **Oportunidades**: Features engineered podem capturar relações não-lineares\n",
        "\n",
        "### Próximos Passos:\n",
        "\n",
        "• **Modelagem**: Aplicar algoritmos de classificação/regressão\n",
        "• **Validação**: Implementar validação cruzada estratificada para lidar com desbalanceamento\n",
        "• **Otimização**: Realizar tuning de hiperparâmetros e seleção de features\n",
        "• **Interpretabilidade**: Analisar importância das features e SHAP values\n",
        "• **Avaliação**: Usar métricas apropriadas (F1-score, precision/recall por classe)\n",
        "• **Deployment**: Preparar modelo para produção com pipeline de pré-processamento"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}