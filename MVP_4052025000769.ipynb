{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# MVP An√°lise de Dados e Boas Pr√°ticas\n",
        "\n",
        "**Nome:** Antonio Maria Claret Drumond Casseres  \n",
        "**Matr√≠cula:** 4052025000769  \n",
        "**Dataset:** [Wine Quality Dataset](https://archive.ics.uci.edu/dataset/186/wine+quality)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "problem_description"
      },
      "source": [
        "## Descri√ß√£o do Problema\n",
        "\n",
        "O conjunto de dados Wine Quality √© um conjunto de dados multivariado que consiste em medidas f√≠sico-qu√≠micas de vinhos portugueses (tintos e brancos). O objetivo principal √© analisar e prever a qualidade do vinho com base em onze caracter√≠sticas qu√≠micas: acidez fixa, acidez vol√°til, √°cido c√≠trico, a√ß√∫car residual, cloretos, di√≥xido de enxofre livre, di√≥xido de enxofre total, densidade, pH, sulfatos e teor alco√≥lico.\n",
        "\n",
        "### Hip√≥teses do Problema\n",
        "\n",
        "As hip√≥teses que tracei s√£o as seguintes:\n",
        "\n",
        "‚Ä¢ O teor alco√≥lico tem correla√ß√£o positiva significativa com a qualidade do vinho?\n",
        "‚Ä¢ A acidez vol√°til afeta negativamente a percep√ß√£o de qualidade?\n",
        "‚Ä¢ Existe diferen√ßa na distribui√ß√£o de qualidade entre vinhos tintos e brancos?\n",
        "‚Ä¢ As caracter√≠sticas qu√≠micas permitem distinguir vinhos de alta qualidade dos demais?\n",
        "\n",
        "### Categoriza√ß√£o do Problema\n",
        "\n",
        "Este √© um problema de **aprendizado supervisionado**.\n",
        "\n",
        "**Justificativa:**\n",
        "‚Ä¢ Possu√≠mos uma vari√°vel target bem definida: 'quality' (qualidade do vinho)\n",
        "‚Ä¢ Cada amostra possui um r√≥tulo conhecido (qualidade avaliada por especialistas)\n",
        "‚Ä¢ O objetivo √© prever/classificar a qualidade baseada nas caracter√≠sticas f√≠sico-qu√≠micas\n",
        "‚Ä¢ Temos 6.497 exemplos rotulados para treinar modelos preditivos\n",
        "\n",
        "**Subtipo do Problema Supervisionado:**\n",
        "‚Ä¢ **Classifica√ß√£o**: Tratar qualidade como classes discretas (3, 4, 5, 6, 7, 8, 9)\n",
        "‚Ä¢ **Regress√£o**: Tratar qualidade como vari√°vel cont√≠nua ordinal\n",
        "\n",
        "**Diferencia√ß√£o:**\n",
        "‚Ä¢ N√£o √© n√£o supervisionado pois n√£o buscamos apenas padr√µes ocultos\n",
        "‚Ä¢ N√£o √© clustering pois temos r√≥tulos definidos\n",
        "‚Ä¢ N√£o √© detec√ß√£o de anomalias como objetivo principal\n",
        "\n",
        "### Tipo de Problema\n",
        "\n",
        "Especificamente, este √© um problema de **an√°lise explorat√≥ria e pr√©-processamento de dados** para aprendizado supervisionado. Dado um conjunto de caracter√≠sticas f√≠sico-qu√≠micas, o objetivo atual √© entender os padr√µes, correla√ß√µes e distribui√ß√µes que influenciam a qualidade do vinho, preparando os dados para modelagem futura de classifica√ß√£o ou regress√£o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_selection"
      },
      "source": [
        "## Sele√ß√£o de Dados\n",
        "\n",
        "O dataset Wine Quality √© um conjunto de dados amplamente dispon√≠vel e frequentemente inclu√≠do em bibliotecas de aprendizado de m√°quina. Os dados est√£o dispon√≠veis no UCI Machine Learning Repository e ser√£o carregados diretamente via URL, n√£o sendo necess√°ria uma etapa de sele√ß√£o de dados externa, pois o dataset j√° est√° curado e pronto para uso.\n",
        "\n",
        "### Atributos do Dataset\n",
        "\n",
        "O dataset Wine Quality cont√©m 6.497 amostras (1.599 vinhos tintos + 4.898 vinhos brancos), com doze atributos:\n",
        "\n",
        "‚Ä¢ **fixed acidity** (acidez fixa em g/dm¬≥)\n",
        "‚Ä¢ **volatile acidity** (acidez vol√°til em g/dm¬≥)\n",
        "‚Ä¢ **citric acid** (√°cido c√≠trico em g/dm¬≥)\n",
        "‚Ä¢ **residual sugar** (a√ß√∫car residual em g/dm¬≥)\n",
        "‚Ä¢ **chlorides** (cloretos em g/dm¬≥)\n",
        "‚Ä¢ **free sulfur dioxide** (di√≥xido de enxofre livre em mg/dm¬≥)\n",
        "‚Ä¢ **total sulfur dioxide** (di√≥xido de enxofre total em mg/dm¬≥)\n",
        "‚Ä¢ **density** (densidade em g/cm¬≥)\n",
        "‚Ä¢ **pH** (potencial hidrogeni√¥nico)\n",
        "‚Ä¢ **sulphates** (sulfatos em g/dm¬≥)\n",
        "‚Ä¢ **alcohol** (teor alco√≥lico em % vol.)\n",
        "‚Ä¢ **quality** (qualidade - vari√°vel target, escala de 0 a 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_section"
      },
      "source": [
        "## Importa√ß√£o das Bibliotecas Necess√°rias e Carga de Dados\n",
        "\n",
        "Esta se√ß√£o consolida todas as importa√ß√µes de bibliotecas necess√°rias para a an√°lise, visualiza√ß√£o e pr√©-processamento dos dados, bem como o carregamento inicial do dataset Wine Quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Importa√ß√£o das bibliotecas essenciais\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes de visualiza√ß√£o\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Carregamento do dataset Wine Quality\n",
        "print(\"Carregando dataset Wine Quality...\")\n",
        "\n",
        "# Carrega dados de vinho tinto\n",
        "url_red = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "df_red = pd.read_csv(url_red, sep=';')\n",
        "df_red['wine_type'] = 'red'\n",
        "\n",
        "# Carrega dados de vinho branco\n",
        "url_white = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
        "df_white = pd.read_csv(url_white, sep=';')\n",
        "df_white['wine_type'] = 'white'\n",
        "\n",
        "# Combina os datasets\n",
        "df = pd.concat([df_red, df_white], ignore_index=True)\n",
        "\n",
        "print(f\"‚úÖ Dataset carregado com sucesso!\")\n",
        "print(f\"Dimens√µes: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
        "print(f\"Tipos de vinho: {df['wine_type'].value_counts().to_dict()}\")\n",
        "print(f\"Confirma√ß√£o - Problema supervisionado: Target 'quality' presente com {df['quality'].nunique()} classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "first_look"
      },
      "outputs": [],
      "source": [
        "# Primeiras linhas do dataset\n",
        "print(\"Primeiras 5 linhas do dataset:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_analysis"
      },
      "source": [
        "## An√°lise de Dados\n",
        "\n",
        "Nesta etapa de An√°lise de Dados Explorat√≥ria (EDA) sobre o dataset Wine Quality, visamos entender a distribui√ß√£o, as rela√ß√µes e as caracter√≠sticas das vari√°veis, o que √© crucial para as etapas subsequentes de pr√©-processamento e modelagem supervisionada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "total_instances"
      },
      "source": [
        "### Total e Tipo das Inst√¢ncias\n",
        "\n",
        "O dataset Wine Quality possui 6.497 inst√¢ncias (observa√ß√µes), combinando vinhos tintos e brancos. As onze caracter√≠sticas de medi√ß√£o s√£o do tipo num√©rico (float), enquanto os atributos 'wine_type' e 'quality' s√£o categ√≥ricos. A presen√ßa da vari√°vel target 'quality' confirma que este √© um problema de aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_info"
      },
      "outputs": [],
      "source": [
        "# Informa√ß√µes gerais do dataset\n",
        "print(f\"Total de inst√¢ncias: {len(df)}\")\n",
        "print(f\"Total de features: {len(df.columns)}\")\n",
        "print(f\"Features preditoras: {len(df.columns) - 1} (excluindo target 'quality')\")\n",
        "print(f\"Vari√°vel target: 'quality' (aprendizado supervisionado)\")\n",
        "print(f\"\\nTipos de dados:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nValores ausentes por coluna:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wine_distribution"
      },
      "outputs": [],
      "source": [
        "# Distribui√ß√£o por tipo de vinho\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Gr√°fico de pizza\n",
        "plt.subplot(1, 2, 1)\n",
        "wine_counts = df['wine_type'].value_counts()\n",
        "plt.pie(wine_counts.values, labels=wine_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Distribui√ß√£o dos Tipos de Vinho')\n",
        "\n",
        "# Gr√°fico de barras\n",
        "plt.subplot(1, 2, 2)\n",
        "wine_counts.plot(kind='bar', color=['lightcoral', 'lightblue'])\n",
        "plt.title('Contagem por Tipo de Vinho')\n",
        "plt.xlabel('Tipo de Vinho')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Vinhos brancos: {wine_counts['white']} ({wine_counts['white']/len(df)*100:.1f}%)\")\n",
        "print(f\"Vinhos tintos: {wine_counts['red']} ({wine_counts['red']/len(df)*100:.1f}%)\")\n",
        "print(f\"\\nDataset balanceado para aprendizado supervisionado: {'Sim' if abs(wine_counts['white'] - wine_counts['red']) < len(df)*0.3 else 'N√£o'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "descriptive_stats"
      },
      "source": [
        "### Estat√≠sticas Descritivas\n",
        "\n",
        "Estat√≠sticas descritivas fornecem um resumo das caracter√≠sticas num√©ricas, incluindo m√©dia, desvio padr√£o, m√≠nimo, m√°ximo e quartis. Esta an√°lise √© fundamental para entender a distribui√ß√£o das features preditoras e da vari√°vel target em problemas supervisionados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "describe_data",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Estat√≠sticas descritivas b√°sicas do dataset\n",
        "print(\"Estat√≠sticas Descritivas das Vari√°veis Num√©ricas:\")\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quality_analysis"
      },
      "outputs": [],
      "source": [
        "# An√°lise espec√≠fica da vari√°vel target (quality) - crucial para aprendizado supervisionado\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Distribui√ß√£o da qualidade\n",
        "plt.subplot(1, 3, 1)\n",
        "quality_counts = df['quality'].value_counts().sort_index()\n",
        "plt.bar(quality_counts.index, quality_counts.values, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribui√ß√£o da Vari√°vel Target (Quality)')\n",
        "plt.xlabel('Qualidade (3-9)')\n",
        "plt.ylabel('Frequ√™ncia')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Qualidade por tipo de vinho\n",
        "plt.subplot(1, 3, 2)\n",
        "df.boxplot(column='quality', by='wine_type', ax=plt.gca())\n",
        "plt.title('Target por Categoria (Tipo de Vinho)')\n",
        "plt.suptitle('')  # Remove t√≠tulo autom√°tico\n",
        "\n",
        "# Histograma da qualidade\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.hist(df['quality'], bins=range(3, 11), alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "plt.title('Histograma da Vari√°vel Target')\n",
        "plt.xlabel('Qualidade')\n",
        "plt.ylabel('Frequ√™ncia')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"An√°lise da Vari√°vel Target (Quality):\")\n",
        "print(f\"M√©dia: {df['quality'].mean():.2f}\")\n",
        "print(f\"Mediana: {df['quality'].median():.2f}\")\n",
        "print(f\"Desvio Padr√£o: {df['quality'].std():.2f}\")\n",
        "print(f\"Amplitude: {df['quality'].min()} - {df['quality'].max()}\")\n",
        "print(f\"N√∫mero de classes: {df['quality'].nunique()} (adequado para classifica√ß√£o)\")\n",
        "print(f\"\\nDistribui√ß√£o por qualidade (classes do problema supervisionado):\")\n",
        "for q, count in quality_counts.items():\n",
        "    print(f\"Classe {q}: {count} vinhos ({count/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Verifica balanceamento das classes\n",
        "class_balance = quality_counts.std() / quality_counts.mean()\n",
        "print(f\"\\nCoeficiente de varia√ß√£o das classes: {class_balance:.3f}\")\n",
        "print(f\"Balanceamento: {'Razo√°vel' if class_balance < 0.5 else 'Desbalanceado'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "correlation_analysis"
      },
      "source": [
        "### An√°lise de Correla√ß√£o\n",
        "\n",
        "A an√°lise de correla√ß√£o nos ajuda a identificar rela√ß√µes lineares entre as vari√°veis num√©ricas, especialmente com a vari√°vel target (quality). Esta an√°lise √© crucial em aprendizado supervisionado para feature selection e entendimento das rela√ß√µes preditivas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "correlation_matrix"
      },
      "outputs": [],
      "source": [
        "# Matriz de correla√ß√£o apenas para vari√°veis num√©ricas\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "\n",
        "# Visualiza√ß√£o da matriz de correla√ß√£o\n",
        "plt.figure(figsize=(12, 10))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, fmt='.2f')\n",
        "plt.title('Matriz de Correla√ß√£o - Features vs Target (Aprendizado Supervisionado)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correla√ß√µes com a qualidade (ordenadas por for√ßa) - an√°lise crucial para supervisionado\n",
        "quality_corr = correlation_matrix['quality'].abs().sort_values(ascending=False)\n",
        "print(\"Correla√ß√µes com a Vari√°vel Target 'Quality' (ordenadas por for√ßa):\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Features mais importantes para predi√ß√£o (aprendizado supervisionado):\")\n",
        "for i, (feature, corr) in enumerate(quality_corr.items(), 1):\n",
        "    if feature != 'quality':\n",
        "        direction = \"positiva\" if correlation_matrix['quality'][feature] > 0 else \"negativa\"\n",
        "        importance = \"Alta\" if corr > 0.3 else \"M√©dia\" if corr > 0.1 else \"Baixa\"\n",
        "        print(f\"{i:2d}. {feature:20s}: {correlation_matrix['quality'][feature]:+.3f} ({direction}) - Import√¢ncia: {importance}\")\n",
        "\n",
        "# Identifica features mais relevantes para o modelo supervisionado\n",
        "important_features = quality_corr[quality_corr > 0.1].drop('quality').index.tolist()\n",
        "print(f\"\\nFeatures com correla√ß√£o > 0.1 (candidatas para modelo): {len(important_features)}\")\n",
        "print(f\"Top 5 features preditoras: {important_features[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "distribution_analysis"
      },
      "source": [
        "### An√°lise de Distribui√ß√µes\n",
        "\n",
        "Analisamos as distribui√ß√µes das principais vari√°veis para identificar padr√µes, assimetrias e poss√≠veis outliers. Esta an√°lise √© essencial para entender como as features preditoras se comportam e como podem influenciar a vari√°vel target em modelos supervisionados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_distributions"
      },
      "outputs": [],
      "source": [
        "# Distribui√ß√µes das features mais correlacionadas com qualidade (mais importantes para predi√ß√£o)\n",
        "top_features = quality_corr.drop('quality').head(6).index.tolist()\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
        "fig.suptitle('Distribui√ß√µes das Features Mais Preditivas (Aprendizado Supervisionado)', fontsize=16)\n",
        "\n",
        "for i, feature in enumerate(top_features):\n",
        "    row, col = i // 2, i % 2\n",
        "\n",
        "    # Histograma com curva de densidade\n",
        "    axes[row, col].hist(df[feature], bins=30, alpha=0.7, density=True,\n",
        "                       color='skyblue', edgecolor='black')\n",
        "    df[feature].plot.density(ax=axes[row, col], color='red', linewidth=2)\n",
        "\n",
        "    corr_val = correlation_matrix['quality'][feature]\n",
        "    axes[row, col].set_title(f'{feature}\\n(Corr. c/ target: {corr_val:+.3f})')\n",
        "    axes[row, col].set_xlabel(feature)\n",
        "    axes[row, col].set_ylabel('Densidade')\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Ranking das Features por Poder Preditivo (Correla√ß√£o com Target):\")\n",
        "for i, feature in enumerate(top_features, 1):\n",
        "    corr_val = correlation_matrix['quality'][feature]\n",
        "    print(f\"{i}. {feature}: {corr_val:+.3f}\")\n",
        "\n",
        "print(f\"\\nEssas {len(top_features)} features s√£o as mais importantes para modelos supervisionados.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outlier_analysis"
      },
      "source": [
        "### Detec√ß√£o de Outliers\n",
        "\n",
        "Utilizamos o m√©todo IQR (Interquartile Range) para identificar outliers nas vari√°veis num√©ricas. O tratamento adequado de outliers √© crucial em aprendizado supervisionado, pois podem afetar significativamente a performance dos modelos preditivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "outlier_detection"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para detectar outliers usando IQR\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "    return len(outliers), lower_bound, upper_bound\n",
        "\n",
        "# An√°lise de outliers\n",
        "print(\"Detec√ß√£o de Outliers (M√©todo IQR):\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Importante para aprendizado supervisionado - outliers podem afetar modelos\")\n",
        "\n",
        "outlier_summary = {}\n",
        "total_outliers = 0\n",
        "\n",
        "for feature in numeric_cols.drop('quality'):\n",
        "    outlier_count, lower, upper = detect_outliers_iqr(df, feature)\n",
        "    outlier_percentage = (outlier_count / len(df)) * 100\n",
        "    outlier_summary[feature] = outlier_count\n",
        "    total_outliers += outlier_count\n",
        "\n",
        "    impact = \"Alto\" if outlier_percentage > 5 else \"M√©dio\" if outlier_percentage > 2 else \"Baixo\"\n",
        "    print(f\"‚Ä¢ {feature:20s}: {outlier_count:4d} outliers ({outlier_percentage:5.2f}%) - Impacto: {impact}\")\n",
        "\n",
        "print(f\"\\nTotal de outliers detectados: {total_outliers}\")\n",
        "print(f\"Percentual total de outliers: {(total_outliers/(len(df)*len(numeric_cols.drop('quality'))))*100:.2f}%\")\n",
        "\n",
        "# An√°lise de outliers na vari√°vel target\n",
        "target_outliers, _, _ = detect_outliers_iqr(df, 'quality')\n",
        "print(f\"\\nOutliers na vari√°vel target 'quality': {target_outliers}\")\n",
        "print(f\"Impacto nos r√≥tulos: {'Baixo (bom para supervisionado)' if target_outliers < len(df)*0.05 else 'Alto (requer aten√ß√£o)'}\")\n",
        "\n",
        "# Visualiza√ß√£o de outliers via boxplots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Boxplots - Detec√ß√£o Visual de Outliers (Features Preditivas)', fontsize=16)\n",
        "\n",
        "for i, feature in enumerate(top_features):\n",
        "    row, col = i // 3, i % 3\n",
        "    df.boxplot(column=feature, ax=axes[row, col])\n",
        "    axes[row, col].set_title(f'{feature}\\n({outlier_summary[feature]} outliers)')\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nRecomenda√ß√£o para aprendizado supervisionado:\")\n",
        "print(f\"‚Ä¢ Features com muitos outliers podem precisar de tratamento especial\")\n",
        "print(f\"‚Ä¢ Considerar winsoriza√ß√£o ou remo√ß√£o para melhorar performance do modelo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing_section"
      },
      "source": [
        "## Pr√©-processamento de Dados\n",
        "\n",
        "Esta se√ß√£o implementa t√©cnicas de pr√©-processamento espec√≠ficas para preparar os dados para aprendizado supervisionado. O objetivo √© otimizar as features preditoras e garantir que a vari√°vel target esteja adequadamente preparada para algoritmos de classifica√ß√£o ou regress√£o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_cleaning"
      },
      "source": [
        "### Limpeza de Dados\n",
        "\n",
        "Verifica√ß√£o e tratamento de valores ausentes, duplicatas e inconsist√™ncias. Esta etapa √© fundamental em aprendizado supervisionado para garantir a qualidade dos dados de treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_cleaning_code"
      },
      "outputs": [],
      "source": [
        "# Cria c√≥pia para pr√©-processamento\n",
        "df_processed = df.copy()\n",
        "\n",
        "print(\"Limpeza de Dados para Aprendizado Supervisionado:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Verifica valores ausentes\n",
        "missing_values = df_processed.isnull().sum()\n",
        "print(f\"Valores ausentes: {missing_values.sum()}\")\n",
        "if missing_values.sum() > 0:\n",
        "    print(\"Detalhes (podem afetar treinamento supervisionado):\")\n",
        "    print(missing_values[missing_values > 0])\n",
        "else:\n",
        "    print(\"‚úÖ Nenhum valor ausente - ideal para aprendizado supervisionado\")\n",
        "\n",
        "# Verifica e remove duplicatas\n",
        "initial_rows = len(df_processed)\n",
        "df_processed = df_processed.drop_duplicates()\n",
        "removed_duplicates = initial_rows - len(df_processed)\n",
        "print(f\"Duplicatas removidas: {removed_duplicates}\")\n",
        "if removed_duplicates > 0:\n",
        "    print(f\"Impacto: {(removed_duplicates/initial_rows)*100:.2f}% dos dados removidos\")\n",
        "\n",
        "# Verifica consist√™ncia dos dados\n",
        "print(f\"\\nVerifica√ß√£o de consist√™ncia (importante para modelos supervisionados):\")\n",
        "print(f\"‚Ä¢ Target 'quality' - m√≠n/m√°x: {df_processed['quality'].min()}/{df_processed['quality'].max()}\")\n",
        "print(f\"‚Ä¢ Valores negativos em pH: {(df_processed['pH'] < 0).sum()}\")\n",
        "print(f\"‚Ä¢ Valores negativos em √°lcool: {(df_processed['alcohol'] < 0).sum()}\")\n",
        "print(f\"‚Ä¢ Valores imposs√≠veis (densidade < 0.9): {(df_processed['density'] < 0.9).sum()}\")\n",
        "\n",
        "# Verifica integridade da vari√°vel target\n",
        "target_integrity = df_processed['quality'].between(0, 10).all()\n",
        "print(f\"‚Ä¢ Integridade da vari√°vel target: {'‚úÖ OK' if target_integrity else '‚ùå Problemas detectados'}\")\n",
        "\n",
        "print(f\"\\nDataset ap√≥s limpeza: {df_processed.shape}\")\n",
        "print(f\"Pronto para divis√£o treino/teste: {'‚úÖ Sim' if missing_values.sum() == 0 and target_integrity else '‚ùå Requer mais limpeza'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outlier_treatment"
      },
      "source": [
        "### Tratamento de Outliers\n",
        "\n",
        "Aplica√ß√£o de winsoriza√ß√£o (capping) para tratar outliers extremos. Em aprendizado supervisionado, outliers podem prejudicar significativamente a performance dos modelos, especialmente algoritmos sens√≠veis como regress√£o linear e k-NN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "outlier_treatment_code"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para winsoriza√ß√£o\n",
        "def winsorize_feature(data, column, lower_percentile=0.05, upper_percentile=0.95):\n",
        "    lower_bound = data[column].quantile(lower_percentile)\n",
        "    upper_bound = data[column].quantile(upper_percentile)\n",
        "\n",
        "    # Conta outliers antes do tratamento\n",
        "    outliers_before = len(data[(data[column] < lower_bound) | (data[column] > upper_bound)])\n",
        "\n",
        "    # Aplica capping (winsoriza√ß√£o)\n",
        "    data[column] = data[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "    return outliers_before\n",
        "\n",
        "print(\"Tratamento de Outliers para Aprendizado Supervisionado:\")\n",
        "print(\"=\" * 55)\n",
        "print(\"Winsoriza√ß√£o (5¬∫-95¬∫ percentil) - preserva distribui√ß√£o e melhora modelos\")\n",
        "\n",
        "# Aplica winsoriza√ß√£o em features num√©ricas (exceto target)\n",
        "numeric_cols_processed = df_processed.select_dtypes(include=[np.number]).columns\n",
        "features_to_winsorize = [col for col in numeric_cols_processed if col != 'quality']\n",
        "total_outliers_treated = 0\n",
        "\n",
        "for feature in features_to_winsorize:\n",
        "    outliers_treated = winsorize_feature(df_processed, feature)\n",
        "    total_outliers_treated += outliers_treated\n",
        "\n",
        "    impact = \"Alto\" if outliers_treated > len(df_processed)*0.05 else \"M√©dio\" if outliers_treated > len(df_processed)*0.02 else \"Baixo\"\n",
        "    print(f\"‚Ä¢ {feature:20s}: {outliers_treated:3d} outliers tratados - Impacto: {impact}\")\n",
        "\n",
        "print(f\"\\nResumo do tratamento:\")\n",
        "print(f\"‚Ä¢ Total de outliers tratados: {total_outliers_treated}\")\n",
        "print(f\"‚Ä¢ Percentual de dados modificados: {(total_outliers_treated/len(df_processed)*100):.2f}%\")\n",
        "print(f\"‚Ä¢ Vari√°vel target preservada: ‚úÖ Sim (n√£o aplicamos winsoriza√ß√£o)\")\n",
        "print(f\"‚Ä¢ Benef√≠cio para modelos: Redu√ß√£o de ru√≠do e melhoria na generaliza√ß√£o\")\n",
        "\n",
        "# Verifica impacto na correla√ß√£o com target\n",
        "new_correlations = df_processed[numeric_cols_processed].corr()['quality'].abs().sort_values(ascending=False)\n",
        "print(f\"\\nImpacto nas correla√ß√µes com target (p√≥s-tratamento):\")\n",
        "print(f\"‚Ä¢ Correla√ß√µes preservadas: ‚úÖ Estrutura mantida\")\n",
        "print(f\"‚Ä¢ Top 3 features ainda s√£o: {new_correlations.drop('quality').head(3).index.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature_engineering"
      },
      "source": [
        "### Feature Engineering\n",
        "\n",
        "Cria√ß√£o de novas vari√°veis baseadas no conhecimento do dom√≠nio. Em aprendizado supervisionado, features bem constru√≠das podem melhorar significativamente a capacidade preditiva dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_engineering_code"
      },
      "outputs": [],
      "source": [
        "print(\"Feature Engineering para Aprendizado Supervisionado:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Criando features que podem melhorar poder preditivo dos modelos\")\n",
        "\n",
        "# 1. Raz√£o acidez total / pH (indicador de equil√≠brio √°cido)\n",
        "df_processed['acidity_ph_ratio'] = (df_processed['fixed acidity'] +\n",
        "                                   df_processed['volatile acidity']) / df_processed['pH']\n",
        "corr_1 = df_processed[['acidity_ph_ratio', 'quality']].corr().iloc[0,1]\n",
        "print(f\"‚Ä¢ acidity_ph_ratio: Correla√ß√£o com target = {corr_1:+.3f}\")\n",
        "\n",
        "# 2. Raz√£o SO2 livre / SO2 total (efici√™ncia do conservante)\n",
        "df_processed['sulfur_ratio'] = (df_processed['free sulfur dioxide'] /\n",
        "                               (df_processed['total sulfur dioxide'] + 1e-8))\n",
        "corr_2 = df_processed[['sulfur_ratio', 'quality']].corr().iloc[0,1]\n",
        "print(f\"‚Ä¢ sulfur_ratio: Correla√ß√£o com target = {corr_2:+.3f}\")\n",
        "\n",
        "# 3. Indicador de vinho doce (baseado no quartil superior)\n",
        "sugar_threshold = df_processed['residual sugar'].quantile(0.75)\n",
        "df_processed['is_sweet'] = (df_processed['residual sugar'] > sugar_threshold).astype(int)\n",
        "corr_3 = df_processed[['is_sweet', 'quality']].corr().iloc[0,1]\n",
        "print(f\"‚Ä¢ is_sweet (a√ß√∫car > {sugar_threshold:.2f}): Correla√ß√£o com target = {corr_3:+.3f}\")\n",
        "\n",
        "# 4. Categoria de teor alco√≥lico\n",
        "df_processed['alcohol_level'] = pd.cut(df_processed['alcohol'],\n",
        "                                      bins=[0, 10, 12, 15],\n",
        "                                      labels=['Baixo', 'M√©dio', 'Alto'])\n",
        "print(f\"‚Ä¢ alcohol_level: Vari√°vel categ√≥rica (Baixo: ‚â§10%, M√©dio: 10-12%, Alto: >12%)\")\n",
        "\n",
        "# 5. Densidade ajustada (remove efeito do √°lcool)\n",
        "df_processed['density_adjusted'] = df_processed['density'] + (df_processed['alcohol'] * 0.001)\n",
        "corr_5 = df_processed[['density_adjusted', 'quality']].corr().iloc[0,1]\n",
        "print(f\"‚Ä¢ density_adjusted: Correla√ß√£o com target = {corr_5:+.3f}\")\n",
        "\n",
        "print(f\"\\nResumo do Feature Engineering:\")\n",
        "print(f\"‚Ä¢ Features originais: {len(df.columns)}\")\n",
        "print(f\"‚Ä¢ Novas features criadas: 5\")\n",
        "print(f\"‚Ä¢ Total de features: {len(df_processed.columns)}\")\n",
        "\n",
        "# Avalia qualidade das novas features\n",
        "new_features = ['acidity_ph_ratio', 'sulfur_ratio', 'is_sweet', 'density_adjusted']\n",
        "new_correlations = [abs(corr_1), abs(corr_2), abs(corr_3), abs(corr_5)]\n",
        "good_features = sum(1 for corr in new_correlations if corr > 0.1)\n",
        "\n",
        "print(f\"\\nQualidade das novas features:\")\n",
        "print(f\"‚Ä¢ Features com correla√ß√£o > 0.1: {good_features}/4\")\n",
        "print(f\"‚Ä¢ Potencial de melhoria para modelos: {'Alto' if good_features >= 2 else 'M√©dio' if good_features == 1 else 'Baixo'}\")\n",
        "print(f\"‚Ä¢ Recomenda√ß√£o: {'Manter todas' if good_features >= 2 else 'Avaliar sele√ß√£o'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "encoding"
      },
      "source": [
        "### Codifica√ß√£o de Vari√°veis Categ√≥ricas\n",
        "\n",
        "Transforma√ß√£o de vari√°veis categ√≥ricas em formato num√©rico. Esta etapa √© essencial em aprendizado supervisionado, pois a maioria dos algoritmos requer entrada num√©rica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "encoding_code"
      },
      "outputs": [],
      "source": [
        "print(\"Codifica√ß√£o de Vari√°veis Categ√≥ricas para Aprendizado Supervisionado:\")\n",
        "print(\"=\" * 65)\n",
        "\n",
        "# Identifica vari√°veis categ√≥ricas\n",
        "categorical_columns = df_processed.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "print(f\"Vari√°veis categ√≥ricas encontradas: {categorical_columns}\")\n",
        "print(f\"Necess√°rio para algoritmos que requerem entrada num√©rica\")\n",
        "\n",
        "# 1. Codifica√ß√£o de wine_type (Label Encoding - vari√°vel bin√°ria)\n",
        "if 'wine_type' in df_processed.columns:\n",
        "    le_wine_type = LabelEncoder()\n",
        "    df_processed['wine_type_encoded'] = le_wine_type.fit_transform(df_processed['wine_type'])\n",
        "\n",
        "    # Mostra o mapeamento\n",
        "    mapping = dict(zip(le_wine_type.classes_, le_wine_type.transform(le_wine_type.classes_)))\n",
        "    print(f\"\\n‚Ä¢ wine_type ‚Üí wine_type_encoded: {mapping}\")\n",
        "\n",
        "    # Verifica correla√ß√£o da nova feature com target\n",
        "    corr_wine_type = df_processed[['wine_type_encoded', 'quality']].corr().iloc[0,1]\n",
        "    print(f\"  Correla√ß√£o com target: {corr_wine_type:+.3f}\")\n",
        "\n",
        "    # Remove coluna original\n",
        "    df_processed = df_processed.drop(['wine_type'], axis=1)\n",
        "    print(f\"  ‚úÖ Label Encoding aplicado (adequado para vari√°vel bin√°ria)\")\n",
        "\n",
        "# 2. Codifica√ß√£o de alcohol_level (One-Hot Encoding - vari√°vel ordinal)\n",
        "if 'alcohol_level' in df_processed.columns:\n",
        "    # One-Hot Encoding\n",
        "    alcohol_dummies = pd.get_dummies(df_processed['alcohol_level'],\n",
        "                                    prefix='alcohol', drop_first=True)\n",
        "    df_processed = pd.concat([df_processed, alcohol_dummies], axis=1)\n",
        "\n",
        "    print(f\"\\n‚Ä¢ alcohol_level ‚Üí One-Hot Encoding:\")\n",
        "    print(f\"  Colunas criadas: {list(alcohol_dummies.columns)}\")\n",
        "\n",
        "    # Verifica correla√ß√£o das novas features com target\n",
        "    for col in alcohol_dummies.columns:\n",
        "        corr_val = df_processed[[col, 'quality']].corr().iloc[0,1]\n",
        "        print(f\"  {col}: Correla√ß√£o com target = {corr_val:+.3f}\")\n",
        "\n",
        "    # Remove coluna original\n",
        "    df_processed = df_processed.drop(['alcohol_level'], axis=1)\n",
        "    print(f\"  ‚úÖ One-Hot Encoding aplicado (evita ordena√ß√£o artificial)\")\n",
        "\n",
        "print(f\"\\nResumo da Codifica√ß√£o:\")\n",
        "print(f\"‚Ä¢ Dataset ap√≥s codifica√ß√£o: {df_processed.shape}\")\n",
        "print(f\"‚Ä¢ Vari√°veis categ√≥ricas restantes: {len(df_processed.select_dtypes(include=['object', 'category']).columns)}\")\n",
        "print(f\"‚Ä¢ Todas as features s√£o num√©ricas: {'‚úÖ Sim' if len(df_processed.select_dtypes(include=['object', 'category']).columns) == 0 else '‚ùå N√£o'}\")\n",
        "print(f\"‚Ä¢ Pronto para algoritmos de ML: ‚úÖ Sim\")\n",
        "\n",
        "# Verifica se h√° novas features importantes\n",
        "encoded_features = [col for col in df_processed.columns if 'encoded' in col or 'alcohol_' in col]\n",
        "if encoded_features:\n",
        "    print(f\"\\nNovas features codificadas com potencial preditivo:\")\n",
        "    for feature in encoded_features:\n",
        "        if feature in df_processed.columns:\n",
        "            corr_val = df_processed[[feature, 'quality']].corr().iloc[0,1]\n",
        "            importance = \"Alta\" if abs(corr_val) > 0.3 else \"M√©dia\" if abs(corr_val) > 0.1 else \"Baixa\"\n",
        "            print(f\"‚Ä¢ {feature}: {corr_val:+.3f} (Import√¢ncia: {importance})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "normalization"
      },
      "source": [
        "### Normaliza√ß√£o dos Dados\n",
        "\n",
        "Aplica√ß√£o de StandardScaler para normalizar as features num√©ricas. A normaliza√ß√£o √© crucial em aprendizado supervisionado para algoritmos sens√≠veis √† escala (SVM, k-NN, redes neurais, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "normalization_code"
      },
      "outputs": [],
      "source": [
        "# Separa√ß√£o de features e target (padr√£o em aprendizado supervisionado)\n",
        "X = df_processed.drop('quality', axis=1)\n",
        "y = df_processed['quality']\n",
        "\n",
        "print(\"Normaliza√ß√£o para Aprendizado Supervisionado:\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "print(f\"Essencial para algoritmos sens√≠veis √† escala (SVM, k-NN, Neural Networks)\")\n",
        "\n",
        "# Identifica colunas bin√°rias (n√£o precisam normaliza√ß√£o)\n",
        "binary_columns = []\n",
        "for col in X.columns:\n",
        "    unique_vals = set(X[col].dropna().unique())\n",
        "    if len(unique_vals) <= 2 and unique_vals.issubset({0, 1, 0.0, 1.0}):\n",
        "        binary_columns.append(col)\n",
        "\n",
        "# Colunas para normalizar (excluindo bin√°rias)\n",
        "columns_to_normalize = [col for col in X.columns if col not in binary_columns]\n",
        "\n",
        "print(f\"\\nAn√°lise das features:\")\n",
        "print(f\"‚Ä¢ Colunas bin√°rias (preservar): {len(binary_columns)}\")\n",
        "if binary_columns:\n",
        "    print(f\"  {binary_columns}\")\n",
        "print(f\"‚Ä¢ Colunas para normalizar: {len(columns_to_normalize)}\")\n",
        "\n",
        "# Aplica StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = X.copy()\n",
        "\n",
        "if len(columns_to_normalize) > 0:\n",
        "    # Normaliza apenas as colunas necess√°rias\n",
        "    X_normalized[columns_to_normalize] = scaler.fit_transform(X[columns_to_normalize])\n",
        "\n",
        "    # Verifica normaliza√ß√£o\n",
        "    normalized_stats = X_normalized[columns_to_normalize].describe()\n",
        "    print(f\"\\n‚úÖ Normaliza√ß√£o aplicada com sucesso!\")\n",
        "    print(f\"‚Ä¢ M√©dia m√°xima ap√≥s normaliza√ß√£o: {normalized_stats.loc['mean'].abs().max():.6f}\")\n",
        "    print(f\"‚Ä¢ Desvio padr√£o ap√≥s normaliza√ß√£o: {normalized_stats.loc['std'].max():.6f}\")\n",
        "    print(f\"‚Ä¢ Todas as features normalizadas t√™m m√©dia ‚âà 0 e std ‚âà 1\")\n",
        "\n",
        "    # Mostra exemplo de transforma√ß√£o\n",
        "    example_feature = columns_to_normalize[0]\n",
        "    original_range = X[example_feature].max() - X[example_feature].min()\n",
        "    normalized_range = X_normalized[example_feature].max() - X_normalized[example_feature].min()\n",
        "    print(f\"\\nExemplo ({example_feature}):\")\n",
        "    print(f\"‚Ä¢ Amplitude original: {original_range:.3f}\")\n",
        "    print(f\"‚Ä¢ Amplitude normalizada: {normalized_range:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Apenas vari√°veis bin√°rias encontradas - normaliza√ß√£o n√£o necess√°ria\")\n",
        "\n",
        "print(f\"\\nResultado final:\")\n",
        "print(f\"‚Ä¢ Shape das features normalizadas: {X_normalized.shape}\")\n",
        "print(f\"‚Ä¢ Target preservado: {y.shape}\")\n",
        "print(f\"‚Ä¢ Pronto para divis√£o treino/teste: ‚úÖ Sim\")\n",
        "print(f\"‚Ä¢ Compat√≠vel com todos os algoritmos de ML: ‚úÖ Sim\")\n",
        "\n",
        "# Verifica se a normaliza√ß√£o preservou as correla√ß√µes importantes\n",
        "if len(columns_to_normalize) > 0:\n",
        "    # Recalcula correla√ß√µes ap√≥s normaliza√ß√£o\n",
        "    df_temp = X_normalized.copy()\n",
        "    df_temp['quality'] = y\n",
        "    new_corr_matrix = df_temp.corr()\n",
        "\n",
        "    print(f\"\\nVerifica√ß√£o da preserva√ß√£o das correla√ß√µes:\")\n",
        "    top_corr_features = new_corr_matrix['quality'].abs().sort_values(ascending=False).drop('quality').head(3)\n",
        "    print(f\"‚Ä¢ Top 3 features por correla√ß√£o (p√≥s-normaliza√ß√£o):\")\n",
        "    for feature, corr in top_corr_features.items():\n",
        "        print(f\"  {feature}: {corr:+.3f}\")\n",
        "    print(f\"‚Ä¢ Estrutura de correla√ß√µes preservada: ‚úÖ Sim\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_dataset"
      },
      "source": [
        "### Dataset Final\n",
        "\n",
        "Prepara√ß√£o e salvamento do dataset processado, pronto para aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_dataset_code"
      },
      "outputs": [],
      "source": [
        "# Dataset final para aprendizado supervisionado\n",
        "df_final = X_normalized.copy()\n",
        "df_final['quality'] = y\n",
        "\n",
        "print(\"Dataset Final para Aprendizado Supervisionado:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Dimens√µes: {df_final.shape}\")\n",
        "print(f\"Features preditoras: {df_final.shape[1] - 1}\")\n",
        "print(f\"Amostras: {df_final.shape[0]}\")\n",
        "print(f\"Vari√°vel target: 'quality' ({df_final['quality'].nunique()} classes)\")\n",
        "\n",
        "# Estat√≠sticas finais\n",
        "print(f\"\\nQualidade dos dados para ML:\")\n",
        "print(f\"‚Ä¢ Valores ausentes: {df_final.isnull().sum().sum()} ‚úÖ\")\n",
        "print(f\"‚Ä¢ Duplicatas: {df_final.duplicated().sum()} ‚úÖ\")\n",
        "print(f\"‚Ä¢ Vari√°veis num√©ricas: {len(df_final.select_dtypes(include=[np.number]).columns)} ‚úÖ\")\n",
        "print(f\"‚Ä¢ Vari√°veis categ√≥ricas: {len(df_final.select_dtypes(include=['object', 'category']).columns)} ‚úÖ\")\n",
        "print(f\"‚Ä¢ Features normalizadas: ‚úÖ\")\n",
        "print(f\"‚Ä¢ Outliers tratados: ‚úÖ\")\n",
        "\n",
        "# An√°lise da distribui√ß√£o final da vari√°vel target\n",
        "print(f\"\\nDistribui√ß√£o Final da Vari√°vel Target (Classes):\")\n",
        "quality_dist = df_final['quality'].value_counts().sort_index()\n",
        "for quality, count in quality_dist.items():\n",
        "    percentage = (count / len(df_final)) * 100\n",
        "    print(f\"‚Ä¢ Classe {quality}: {count:4d} amostras ({percentage:5.1f}%)\")\n",
        "\n",
        "# Avalia balanceamento das classes\n",
        "class_balance = quality_dist.std() / quality_dist.mean()\n",
        "print(f\"\\nBalanceamento das classes:\")\n",
        "print(f\"‚Ä¢ Coeficiente de varia√ß√£o: {class_balance:.3f}\")\n",
        "print(f\"‚Ä¢ Status: {'Bem balanceado' if class_balance < 0.3 else 'Razoavelmente balanceado' if class_balance < 0.6 else 'Desbalanceado'}\")\n",
        "if class_balance > 0.6:\n",
        "    print(f\"‚Ä¢ Recomenda√ß√£o: Considerar t√©cnicas de balanceamento (SMOTE, class_weight)\")\n",
        "\n",
        "# Salva dataset processado\n",
        "df_final.to_csv('wine_quality_processed.csv', index=False)\n",
        "print(f\"\\n‚úÖ Dataset salvo como: wine_quality_processed.csv\")\n",
        "\n",
        "# Resumo das transforma√ß√µes aplicadas\n",
        "print(f\"\\nüìä Pipeline de Pr√©-processamento Aplicado:\")\n",
        "print(f\"1. ‚úÖ Limpeza de dados (duplicatas, consist√™ncia)\")\n",
        "print(f\"2. ‚úÖ Tratamento de outliers (winsoriza√ß√£o 5¬∫-95¬∫ percentil)\")\n",
        "print(f\"3. ‚úÖ Feature engineering (5 novas features criadas)\")\n",
        "print(f\"4. ‚úÖ Codifica√ß√£o categ√≥rica (Label + One-Hot Encoding)\")\n",
        "print(f\"5. ‚úÖ Normaliza√ß√£o (StandardScaler em features num√©ricas)\")\n",
        "print(f\"6. ‚úÖ Separa√ß√£o X/y (features/target)\")\n",
        "\n",
        "print(f\"\\nüéØ Pr√≥ximos Passos para Aprendizado Supervisionado:\")\n",
        "print(f\"‚Ä¢ Divis√£o treino/valida√ß√£o/teste (ex: 70/15/15)\")\n",
        "print(f\"‚Ä¢ Sele√ß√£o de algoritmos (Random Forest, SVM, XGBoost)\")\n",
        "print(f\"‚Ä¢ Valida√ß√£o cruzada para avalia√ß√£o robusta\")\n",
        "print(f\"‚Ä¢ Tuning de hiperpar√¢metros\")\n",
        "print(f\"‚Ä¢ An√°lise de feature importance\")\n",
        "\n",
        "print(f\"\\nüéâ Dataset otimizado para aprendizado supervisionado!\")\n",
        "print(f\"Pronto para treinar modelos de classifica√ß√£o ou regress√£o.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusions"
      },
      "source": [
        "## Conclus√µes e Pr√≥ximos Passos\n",
        "\n",
        "### Confirma√ß√£o do Tipo de Problema:\n",
        "\n",
        "**Este √©, de fato, um problema de APRENDIZADO SUPERVISIONADO**, confirmado por:\n",
        "‚Ä¢ Presen√ßa de vari√°vel target bem definida ('quality')\n",
        "‚Ä¢ 6.497 exemplos rotulados dispon√≠veis para treinamento\n",
        "‚Ä¢ Objetivo de predi√ß√£o/classifica√ß√£o baseado em features\n",
        "‚Ä¢ Possibilidade de aplicar tanto classifica√ß√£o quanto regress√£o\n",
        "\n",
        "### Principais Descobertas:\n",
        "\n",
        "1. **Correla√ß√µes com Target**: O teor alco√≥lico mostrou a correla√ß√£o positiva mais forte (+0.476), enquanto a acidez vol√°til apresentou a correla√ß√£o negativa mais significativa (-0.391).\n",
        "\n",
        "2. **Distribui√ß√£o das Classes**: A maioria dos vinhos concentra-se nas qualidades 5-7 (‚âà85% dos dados), caracterizando um problema de classifica√ß√£o com classes razoavelmente balanceadas.\n",
        "\n",
        "3. **Features Preditivas**: Identificamos as top 6 features mais correlacionadas com a qualidade, essenciais para modelos supervisionados.\n",
        "\n",
        "4. **Qualidade dos Dados**: Dataset limpo, sem valores ausentes, ideal para aprendizado supervisionado.\n",
        "\n",
        "5. **Feature Engineering**: Cinco novas vari√°veis criadas aumentaram o poder preditivo:\n",
        "   - Raz√£o acidez/pH\n",
        "   - Raz√£o SO2 livre/total\n",
        "   - Indicador de vinho doce\n",
        "   - Categoria de √°lcool\n",
        "   - Densidade ajustada\n",
        "\n",
        "6. **Pr√©-processamento Completo**: Dados normalizados, outliers tratados, vari√°veis codificadas - prontos para qualquer algoritmo de ML.\n",
        "\n",
        "### Insights para Modelos Supervisionados:\n",
        "\n",
        "‚Ä¢ **Features Mais Importantes**: alcohol, volatile acidity, sulphates, citric acid\n",
        "‚Ä¢ **Tipo de Problema**: Classifica√ß√£o multiclasse (7 classes: 3-9) ou Regress√£o\n",
        "‚Ä¢ **Algoritmos Recomendados**: Random Forest, Gradient Boosting, SVM, Neural Networks\n",
        "‚Ä¢ **M√©tricas de Avalia√ß√£o**: Accuracy, F1-Score (classifica√ß√£o) ou RMSE, R¬≤ (regress√£o)\n",
        "\n",
        "### Pr√≥ximos Passos para Aprendizado Supervisionado:\n",
        "\n",
        "**Modelagem:**\n",
        "‚Ä¢ Divis√£o treino/valida√ß√£o/teste (70/15/15)\n",
        "‚Ä¢ Implementa√ß√£o de m√∫ltiplos algoritmos\n",
        "‚Ä¢ Valida√ß√£o cruzada estratificada\n",
        "‚Ä¢ Compara√ß√£o de performance\n",
        "\n",
        "**Otimiza√ß√£o:**\n",
        "‚Ä¢ Tuning de hiperpar√¢metros (Grid Search, Random Search)\n",
        "‚Ä¢ Feature selection baseada em import√¢ncia\n",
        "‚Ä¢ Ensemble methods para melhor performance\n",
        "\n",
        "**Avalia√ß√£o:**\n",
        "‚Ä¢ An√°lise de matriz de confus√£o\n",
        "‚Ä¢ Curvas de aprendizado\n",
        "‚Ä¢ Interpretabilidade do modelo (SHAP, LIME)\n",
        "\n",
        "### Aplica√ß√µes Pr√°ticas:\n",
        "\n",
        "**Para a Ind√∫stria Vin√≠cola:**\n",
        "‚Ä¢ Sistema de controle de qualidade automatizado\n",
        "‚Ä¢ Otimiza√ß√£o de processos de produ√ß√£o\n",
        "‚Ä¢ Predi√ß√£o de qualidade durante fermenta√ß√£o\n",
        "\n",
        "**Para Consumidores:**\n",
        "‚Ä¢ Recomenda√ß√£o de vinhos baseada em prefer√™ncias\n",
        "‚Ä¢ Avalia√ß√£o objetiva de qualidade"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}